{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-02T05:26:16.078620Z",
     "iopub.status.busy": "2025-04-02T05:26:16.078207Z",
     "iopub.status.idle": "2025-04-02T05:26:16.917899Z",
     "shell.execute_reply": "2025-04-02T05:26:16.916916Z",
     "shell.execute_reply.started": "2025-04-02T05:26:16.078583Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Image-Tagging'...\n",
      "remote: Enumerating objects: 113, done.\u001b[K\n",
      "remote: Counting objects: 100% (113/113), done.\u001b[K\n",
      "remote: Compressing objects: 100% (83/83), done.\u001b[K\n",
      "remote: Total 113 (delta 49), reused 89 (delta 25), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (113/113), 78.20 KiB | 2.79 MiB/s, done.\n",
      "Resolving deltas: 100% (49/49), done.\n"
     ]
    }
   ],
   "source": [
    "# Please add COCO2017 and PASCAL VOC2007 Dataset before running on Kaggle\n",
    "!git clone https://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@github.com/ntkhoang/Image-Tagging.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T05:26:19.410289Z",
     "iopub.status.busy": "2025-04-02T05:26:19.409990Z",
     "iopub.status.idle": "2025-04-02T05:26:19.416593Z",
     "shell.execute_reply": "2025-04-02T05:26:19.415772Z",
     "shell.execute_reply.started": "2025-04-02T05:26:19.410265Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/Image-Tagging\n"
     ]
    }
   ],
   "source": [
    "%cd Image-Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T05:26:21.388905Z",
     "iopub.status.busy": "2025-04-02T05:26:21.388586Z",
     "iopub.status.idle": "2025-04-02T05:26:31.832550Z",
     "shell.execute_reply": "2025-04-02T05:26:31.831570Z",
     "shell.execute_reply.started": "2025-04-02T05:26:21.388879Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (2.5.1+cu121)\n",
      "Requirement already satisfied: torchvision>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (0.20.1+cu121)\n",
      "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (11.0.0)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (4.67.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (1.2.2)\n",
      "Requirement already satisfied: matplotlib>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (3.7.5)\n",
      "Collecting gradio>=4.0.0 (from -r requirements.txt (line 8))\n",
      "  Downloading gradio-5.23.3-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (2024.12.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.0.0->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.20.0->-r requirements.txt (line 3)) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.20.0->-r requirements.txt (line 3)) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.20.0->-r requirements.txt (line 3)) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.20.0->-r requirements.txt (line 3)) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.20.0->-r requirements.txt (line 3)) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.20.0->-r requirements.txt (line 3)) (2.4.1)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->-r requirements.txt (line 6)) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->-r requirements.txt (line 6)) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->-r requirements.txt (line 6)) (3.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->-r requirements.txt (line 7)) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->-r requirements.txt (line 7)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->-r requirements.txt (line 7)) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->-r requirements.txt (line 7)) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->-r requirements.txt (line 7)) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->-r requirements.txt (line 7)) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->-r requirements.txt (line 7)) (2.9.0.post0)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->-r requirements.txt (line 8)) (22.1.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->-r requirements.txt (line 8)) (3.7.1)\n",
      "Collecting fastapi<1.0,>=0.115.2 (from gradio>=4.0.0->-r requirements.txt (line 8))\n",
      "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting ffmpy (from gradio>=4.0.0->-r requirements.txt (line 8))\n",
      "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting gradio-client==1.8.0 (from gradio>=4.0.0->-r requirements.txt (line 8))\n",
      "  Downloading gradio_client-1.8.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting groovy~=0.1 (from gradio>=4.0.0->-r requirements.txt (line 8))\n",
      "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->-r requirements.txt (line 8)) (0.28.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->-r requirements.txt (line 8)) (0.29.0)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->-r requirements.txt (line 8)) (3.0.2)\n",
      "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->-r requirements.txt (line 8)) (3.10.12)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->-r requirements.txt (line 8)) (2.2.3)\n",
      "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->-r requirements.txt (line 8)) (2.11.0a2)\n",
      "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->-r requirements.txt (line 8)) (0.25.1)\n",
      "Collecting python-multipart>=0.0.18 (from gradio>=4.0.0->-r requirements.txt (line 8))\n",
      "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->-r requirements.txt (line 8)) (6.0.2)\n",
      "Collecting ruff>=0.9.3 (from gradio>=4.0.0->-r requirements.txt (line 8))\n",
      "  Downloading ruff-0.11.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
      "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio>=4.0.0->-r requirements.txt (line 8))\n",
      "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio>=4.0.0->-r requirements.txt (line 8))\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting starlette<1.0,>=0.40.0 (from gradio>=4.0.0->-r requirements.txt (line 8))\n",
      "  Downloading starlette-0.46.1-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio>=4.0.0->-r requirements.txt (line 8))\n",
      "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->-r requirements.txt (line 8)) (0.15.1)\n",
      "Collecting uvicorn>=0.14.0 (from gradio>=4.0.0->-r requirements.txt (line 8))\n",
      "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.8.0->gradio>=4.0.0->-r requirements.txt (line 8)) (14.1)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio>=4.0.0->-r requirements.txt (line 8)) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio>=4.0.0->-r requirements.txt (line 8)) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio>=4.0.0->-r requirements.txt (line 8)) (1.2.2)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio>=4.0.0->-r requirements.txt (line 8)) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio>=4.0.0->-r requirements.txt (line 8)) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio>=4.0.0->-r requirements.txt (line 8)) (0.14.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.28.1->gradio>=4.0.0->-r requirements.txt (line 8)) (2.32.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio>=4.0.0->-r requirements.txt (line 8)) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio>=4.0.0->-r requirements.txt (line 8)) (2025.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2.12,>=2.0->gradio>=4.0.0->-r requirements.txt (line 8)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.29.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2.12,>=2.0->gradio>=4.0.0->-r requirements.txt (line 8)) (2.29.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.5.0->-r requirements.txt (line 7)) (1.17.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio>=4.0.0->-r requirements.txt (line 8)) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio>=4.0.0->-r requirements.txt (line 8)) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio>=4.0.0->-r requirements.txt (line 8)) (13.9.4)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.20.0->-r requirements.txt (line 3)) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.20.0->-r requirements.txt (line 3)) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.20.0->-r requirements.txt (line 3)) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.20.0->-r requirements.txt (line 3)) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.20.0->-r requirements.txt (line 3)) (2024.2.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.0.0->-r requirements.txt (line 8)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.0.0->-r requirements.txt (line 8)) (2.19.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.28.1->gradio>=4.0.0->-r requirements.txt (line 8)) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.28.1->gradio>=4.0.0->-r requirements.txt (line 8)) (2.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.0.0->-r requirements.txt (line 8)) (0.1.2)\n",
      "Downloading gradio-5.23.3-py3-none-any.whl (46.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.5/46.5 MB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading gradio_client-1.8.0-py3-none-any.whl (322 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.2/322.2 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
      "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Downloading ruff-0.11.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m101.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
      "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Downloading starlette-0.46.1-py3-none-any.whl (71 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
      "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
      "Installing collected packages: uvicorn, tomlkit, semantic-version, ruff, python-multipart, groovy, ffmpy, starlette, safehttpx, gradio-client, fastapi, gradio\n",
      "Successfully installed fastapi-0.115.12 ffmpy-0.5.0 gradio-5.23.3 gradio-client-1.8.0 groovy-0.1.2 python-multipart-0.0.20 ruff-0.11.2 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.1 tomlkit-0.13.2 uvicorn-0.34.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T05:26:31.834169Z",
     "iopub.status.busy": "2025-04-02T05:26:31.833831Z",
     "iopub.status.idle": "2025-04-02T05:26:39.646367Z",
     "shell.execute_reply": "2025-04-02T05:26:39.645554Z",
     "shell.execute_reply.started": "2025-04-02T05:26:31.834133Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.29.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n",
      "Collecting torch-geometric\n",
      "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.11.12)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2024.12.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.26.4)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
      "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.2.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.67.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.18.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->torch-geometric) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->torch-geometric) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->torch-geometric) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->torch-geometric) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->torch-geometric) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->torch-geometric) (2.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2025.1.31)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch-geometric) (4.12.2)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torch-geometric) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torch-geometric) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->torch-geometric) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->torch-geometric) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->torch-geometric) (2024.2.0)\n",
      "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torch-geometric\n",
      "Successfully installed torch-geometric-2.6.1\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install torch-geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T07:24:21.189832Z",
     "iopub.status.busy": "2025-04-01T07:24:21.189488Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Number of available GPUs: 2\n",
      "Detected COCO-style dataset structure\n",
      "Loading annotations from /kaggle/input/coco-2017-dataset/coco2017/annotations/instances_train2017.json\n",
      "Processing 117266 images with annotations...\n",
      "Loaded 117266 images with 80 classes\n",
      "Class names: ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light']...\n",
      "Train set: 93812 images\n",
      "Validation set: 11727 images\n",
      "Test set: 11727 images\n",
      "Using image size: 512x512\n",
      "Using effective batch size of 64 with 2 GPUs\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n",
      "100%|███████████████████████████████████████| 97.8M/97.8M [00:00<00:00, 188MB/s]\n",
      "Using DataParallel for multi-GPU training\n",
      "Model Architecture: DataParallel(\n",
      "  (module): ImageGCNSimple(\n",
      "    (feature_extractor): Sequential(\n",
      "      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "      (4): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (5): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (6): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (4): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (5): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (7): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    )\n",
      "    (gcn): SimplifiedGCN(\n",
      "      (fc1): Linear(in_features=2048, out_features=512, bias=True)\n",
      "      (fc2): Linear(in_features=512, out_features=80, bias=True)\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (projection): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "  )\n",
      ")\n",
      "Total parameters: 28,794,512\n",
      "Trainable parameters: 5,286,480\n",
      "Starting training...\n",
      "Training: 100%|█████████████████████████████| 1466/1466 [31:05<00:00,  1.27s/it]\n",
      "Evaluating: 100%|█████████████████████████████| 184/184 [02:46<00:00,  1.10it/s]\n",
      "Epoch 1/30:\n",
      "  Train Loss: 0.0833\n",
      "  Val F1: 0.4358, Precision: 0.7210, Recall: 0.3578, Accuracy: 0.9769\n",
      "  New best model saved to ./models/best_model.pth\n",
      "Training:  61%|██████████████████▎           | 896/1466 [16:37<09:30,  1.00s/it]"
     ]
    }
   ],
   "source": [
    "!python train_coco.py --data-dir /kaggle/input/coco-2017-dataset/coco2017 --batch-size 32 --device cuda --epochs 30 --max-images 999999 --image-size 512 --train-half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T06:25:17.724701Z",
     "iopub.status.busy": "2025-04-02T06:25:17.724357Z",
     "iopub.status.idle": "2025-04-02T06:25:55.868220Z",
     "shell.execute_reply": "2025-04-02T06:25:55.867402Z",
     "shell.execute_reply.started": "2025-04-02T06:25:17.724675Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Looking for images in possible locations:\n",
      "  - /kaggle/input/coco-2017-dataset/coco2017/val2017\n",
      "  - /kaggle/input/coco-2017-dataset/coco2017/coco2017/val2017\n",
      "  - /kaggle/input/coco-2017-dataset/coco2017/images/val2017\n",
      "  - /kaggle/input/coco-2017-dataset/coco2017\n",
      "Found images in: /kaggle/input/coco-2017-dataset/coco2017/val2017\n",
      "Looking for annotation files in possible locations:\n",
      "  - /kaggle/input/coco-2017-dataset/coco2017/annotations/instances_val2017.json\n",
      "  - /kaggle/input/coco-2017-dataset/coco2017/coco2017/annotations/instances_val2017.json\n",
      "  - /kaggle/input/coco-2017-dataset/coco2017/instances_val2017.json\n",
      "Found annotations in: /kaggle/input/coco-2017-dataset/coco2017/annotations/instances_val2017.json\n",
      "Loading COCO annotations from /kaggle/input/coco-2017-dataset/coco2017/annotations/instances_val2017.json\n",
      "Processing val2017: 100%|██████████████████| 4952/4952 [00:08<00:00, 570.33it/s]\n",
      "Loaded 4952 images with 80 categories\n",
      "Loading model weights from /kaggle/input/best_coco_new/pytorch/default/1/best_model_coco_new.pth\n",
      "Model loaded successfully\n",
      "Evaluating model on COCO val2017 dataset...\n",
      "Evaluating: 100%|█████████████████████████████| 619/619 [00:21<00:00, 28.80it/s]\n",
      "\n",
      "Evaluation Results:\n",
      "Accuracy: 0.9708\n",
      "Precision: 0.5822\n",
      "Recall: 0.4761\n",
      "F1 Score: 0.4921\n",
      "mAP: 0.5383\n",
      "\n",
      "Top 5 classes:\n",
      "  person: F1=0.8658, Precision=0.8431, Recall=0.8897\n",
      "  elephant: F1=0.8690, Precision=0.9241, Recall=0.8202\n",
      "  airplane: F1=0.8701, Precision=0.9625, Recall=0.7938\n",
      "  tennis racket: F1=0.8746, Precision=0.9444, Recall=0.8144\n",
      "  zebra: F1=0.8903, Precision=0.9857, Recall=0.8118\n",
      "\n",
      "Bottom 5 classes:\n",
      "  parking meter: F1=0.0000, Precision=0.0000, Recall=0.0000\n",
      "  toaster: F1=0.0000, Precision=0.0000, Recall=0.0000\n",
      "  toothbrush: F1=0.0000, Precision=0.0000, Recall=0.0000\n",
      "  hair drier: F1=0.0000, Precision=0.0000, Recall=0.0000\n",
      "  scissors: F1=0.0690, Precision=1.0000, Recall=0.0357\n"
     ]
    }
   ],
   "source": [
    "!python evaluate_coco.py --coco-dir /kaggle/input/coco-2017-dataset/coco2017 --model-path /kaggle/input/best_coco_new/pytorch/default/1/best_model_coco_new.pth --device cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T05:34:39.888387Z",
     "iopub.status.busy": "2025-04-02T05:34:39.888078Z",
     "iopub.status.idle": "2025-04-02T05:53:31.497947Z",
     "shell.execute_reply": "2025-04-02T05:53:31.496903Z",
     "shell.execute_reply.started": "2025-04-02T05:34:39.888362Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Number of available GPUs: 2\n",
      "Looking for VOC data in:\n",
      "  Images: /kaggle/input/pascal-voc-2007/VOCtrainval_06-Nov-2007/VOCdevkit/VOC2007/JPEGImages\n",
      "  Annotations: /kaggle/input/pascal-voc-2007/VOCtrainval_06-Nov-2007/VOCdevkit/VOC2007/Annotations\n",
      "  Split file: /kaggle/input/pascal-voc-2007/VOCtrainval_06-Nov-2007/VOCdevkit/VOC2007/ImageSets/Main/trainval.txt\n",
      "Processing 5011 images from trainval split...\n",
      "Loaded 5011 images with 20 classes\n",
      "Test split file not found: /kaggle/input/pascal-voc-2007/VOCtrainval_06-Nov-2007/VOCdevkit/VOC2007/ImageSets/Main/test.txt\n",
      "Will use a portion of the validation set as the test set\n",
      "Train set: 3507 images\n",
      "Validation set: 751 images\n",
      "Test set: 753 images\n",
      "Using effective batch size of 64 with 2 GPUs\n",
      "Looking for VOC data in:\n",
      "  Images: /kaggle/input/pascal-voc-2007/VOCtrainval_06-Nov-2007/VOCdevkit/VOC2007/JPEGImages\n",
      "  Annotations: /kaggle/input/pascal-voc-2007/VOCtrainval_06-Nov-2007/VOCdevkit/VOC2007/Annotations\n",
      "  Split file: /kaggle/input/pascal-voc-2007/VOCtrainval_06-Nov-2007/VOCdevkit/VOC2007/ImageSets/Main/trainval.txt\n",
      "Processing 5011 images from trainval split...\n",
      "Loaded 5011 images with 20 classes\n",
      "Creating adjacency matrix from label co-occurrences...\n",
      "Using DataParallel for multi-GPU training\n",
      "Total parameters: 28,763,732\n",
      "Trainable parameters: 5,255,700\n",
      "Starting training for 30 epochs...\n",
      "Training: 100%|█████████████████████████████████| 55/55 [00:37<00:00,  1.46it/s]\n",
      "Evaluating: 100%|███████████████████████████████| 12/12 [00:09<00:00,  1.30it/s]\n",
      "Epoch 1/30:\n",
      "  Train Loss: 0.2149\n",
      "  Val F1: 0.4629, Precision: 0.7005, Recall: 0.3810, Accuracy: 0.9593\n",
      "  New best model saved to ./models/best_model_voc.pth\n",
      "Training: 100%|█████████████████████████████████| 55/55 [00:26<00:00,  2.08it/s]\n",
      "Evaluating: 100%|███████████████████████████████| 12/12 [00:06<00:00,  2.00it/s]\n",
      "Epoch 2/30:\n",
      "  Train Loss: 0.1008\n",
      "  Val F1: 0.7380, Precision: 0.8849, Recall: 0.6723, Accuracy: 0.9722\n",
      "  New best model saved to ./models/best_model_voc.pth\n",
      "Training: 100%|█████████████████████████████████| 55/55 [00:27<00:00,  2.03it/s]\n",
      "Evaluating: 100%|███████████████████████████████| 12/12 [00:06<00:00,  1.78it/s]\n",
      "Epoch 3/30:\n",
      "  Train Loss: 0.0772\n",
      "  Val F1: 0.7842, Precision: 0.9093, Recall: 0.7044, Accuracy: 0.9757\n",
      "  New best model saved to ./models/best_model_voc.pth\n",
      "Training: 100%|█████████████████████████████████| 55/55 [00:27<00:00,  1.96it/s]\n",
      "Evaluating: 100%|███████████████████████████████| 12/12 [00:06<00:00,  1.99it/s]\n",
      "Epoch 4/30:\n",
      "  Train Loss: 0.0689\n",
      "  Val F1: 0.7914, Precision: 0.9200, Recall: 0.7193, Accuracy: 0.9772\n",
      "  New best model saved to ./models/best_model_voc.pth\n",
      "Training: 100%|█████████████████████████████████| 55/55 [00:26<00:00,  2.09it/s]\n",
      "Evaluating: 100%|███████████████████████████████| 12/12 [00:06<00:00,  1.90it/s]\n",
      "Epoch 5/30:\n",
      "  Train Loss: 0.0624\n",
      "  Val F1: 0.8193, Precision: 0.9107, Recall: 0.7578, Accuracy: 0.9781\n",
      "  New best model saved to ./models/best_model_voc.pth\n",
      "  Checkpoint saved to ./models/checkpoint_voc_epoch_5.pth\n",
      "Training: 100%|█████████████████████████████████| 55/55 [00:26<00:00,  2.09it/s]\n",
      "Evaluating: 100%|███████████████████████████████| 12/12 [00:07<00:00,  1.70it/s]\n",
      "Epoch 6/30:\n",
      "  Train Loss: 0.0586\n",
      "  Val F1: 0.8214, Precision: 0.9290, Recall: 0.7569, Accuracy: 0.9790\n",
      "  New best model saved to ./models/best_model_voc.pth\n",
      "Training: 100%|█████████████████████████████████| 55/55 [00:25<00:00,  2.14it/s]\n",
      "Evaluating: 100%|███████████████████████████████| 12/12 [00:07<00:00,  1.68it/s]\n",
      "Epoch 7/30:\n",
      "  Train Loss: 0.0578\n",
      "  Val F1: 0.8181, Precision: 0.9208, Recall: 0.7535, Accuracy: 0.9782\n",
      "Training: 100%|█████████████████████████████████| 55/55 [00:28<00:00,  1.92it/s]\n",
      "Evaluating: 100%|███████████████████████████████| 12/12 [00:06<00:00,  1.88it/s]\n",
      "Epoch 8/30:\n",
      "  Train Loss: 0.0545\n",
      "  Val F1: 0.8173, Precision: 0.8900, Recall: 0.7790, Accuracy: 0.9776\n",
      "Training: 100%|█████████████████████████████████| 55/55 [00:26<00:00,  2.10it/s]\n",
      "Evaluating: 100%|███████████████████████████████| 12/12 [00:06<00:00,  1.92it/s]\n",
      "Epoch 9/30:\n",
      "  Train Loss: 0.0520\n",
      "  Val F1: 0.8012, Precision: 0.9242, Recall: 0.7188, Accuracy: 0.9772\n",
      "Training: 100%|█████████████████████████████████| 55/55 [00:26<00:00,  2.08it/s]\n",
      "Evaluating: 100%|███████████████████████████████| 12/12 [00:06<00:00,  1.93it/s]\n",
      "Epoch 10/30:\n",
      "  Train Loss: 0.0480\n",
      "  Val F1: 0.7997, Precision: 0.9230, Recall: 0.7290, Accuracy: 0.9752\n",
      "  Checkpoint saved to ./models/checkpoint_voc_epoch_10.pth\n",
      "Training: 100%|█████████████████████████████████| 55/55 [00:28<00:00,  1.91it/s]\n",
      "Evaluating: 100%|███████████████████████████████| 12/12 [00:06<00:00,  1.96it/s]\n",
      "Epoch 11/30:\n",
      "  Train Loss: 0.0520\n",
      "  Val F1: 0.8059, Precision: 0.8951, Recall: 0.7597, Accuracy: 0.9763\n",
      "Training: 100%|█████████████████████████████████| 55/55 [00:28<00:00,  1.90it/s]\n",
      "Evaluating: 100%|███████████████████████████████| 12/12 [00:05<00:00,  2.00it/s]\n",
      "Epoch 12/30:\n",
      "  Train Loss: 0.0493\n",
      "  Val F1: 0.7906, Precision: 0.9029, Recall: 0.7330, Accuracy: 0.9728\n",
      "Training: 100%|█████████████████████████████████| 55/55 [00:28<00:00,  1.93it/s]\n",
      "Evaluating: 100%|███████████████████████████████| 12/12 [00:06<00:00,  1.82it/s]\n",
      "Epoch 13/30:\n",
      "  Train Loss: 0.0464\n",
      "  Val F1: 0.8268, Precision: 0.8981, Recall: 0.7720, Accuracy: 0.9784\n",
      "  New best model saved to ./models/best_model_voc.pth\n",
      "Training: 100%|█████████████████████████████████| 55/55 [00:28<00:00,  1.93it/s]\n",
      "Evaluating: 100%|███████████████████████████████| 12/12 [00:06<00:00,  1.90it/s]\n",
      "Epoch 14/30:\n",
      "  Train Loss: 0.0451\n",
      "  Val F1: 0.8230, Precision: 0.8728, Recall: 0.7979, Accuracy: 0.9765\n",
      "Training: 100%|█████████████████████████████████| 55/55 [00:29<00:00,  1.89it/s]\n",
      "Evaluating: 100%|███████████████████████████████| 12/12 [00:06<00:00,  1.98it/s]\n",
      "Epoch 15/30:\n",
      "  Train Loss: 0.0466\n",
      "  Val F1: 0.8017, Precision: 0.8845, Recall: 0.7512, Accuracy: 0.9749\n",
      "  Checkpoint saved to ./models/checkpoint_voc_epoch_15.pth\n",
      "Training: 100%|█████████████████████████████████| 55/55 [00:26<00:00,  2.04it/s]\n",
      "Evaluating: 100%|███████████████████████████████| 12/12 [00:06<00:00,  1.75it/s]\n",
      "Epoch 16/30:\n",
      "  Train Loss: 0.0453\n",
      "  Val F1: 0.8228, Precision: 0.9187, Recall: 0.7619, Accuracy: 0.9772\n",
      "Training: 100%|█████████████████████████████████| 55/55 [00:26<00:00,  2.07it/s]\n",
      "Evaluating: 100%|███████████████████████████████| 12/12 [00:06<00:00,  1.86it/s]\n",
      "Epoch 17/30:\n",
      "  Train Loss: 0.0442\n",
      "  Val F1: 0.8244, Precision: 0.8867, Recall: 0.7844, Accuracy: 0.9778\n",
      "Training: 100%|█████████████████████████████████| 55/55 [00:26<00:00,  2.07it/s]\n",
      "Evaluating: 100%|███████████████████████████████| 12/12 [00:06<00:00,  1.92it/s]\n",
      "Epoch 18/30:\n",
      "  Train Loss: 0.0472\n",
      "  Val F1: 0.8110, Precision: 0.9242, Recall: 0.7496, Accuracy: 0.9774\n",
      "Training: 100%|█████████████████████████████████| 55/55 [00:28<00:00,  1.94it/s]\n",
      "Evaluating: 100%|███████████████████████████████| 12/12 [00:06<00:00,  1.97it/s]\n",
      "Epoch 19/30:\n",
      "  Train Loss: 0.0456\n",
      "  Val F1: 0.8290, Precision: 0.8938, Recall: 0.7863, Accuracy: 0.9785\n",
      "  New best model saved to ./models/best_model_voc.pth\n",
      "Training: 100%|█████████████████████████████████| 55/55 [00:26<00:00,  2.07it/s]\n",
      "Evaluating: 100%|███████████████████████████████| 12/12 [00:05<00:00,  2.01it/s]\n",
      "Epoch 20/30:\n",
      "  Train Loss: 0.0432\n",
      "  Val F1: 0.7999, Precision: 0.9098, Recall: 0.7361, Accuracy: 0.9770\n",
      "  Checkpoint saved to ./models/checkpoint_voc_epoch_20.pth\n",
      "Training: 100%|█████████████████████████████████| 55/55 [00:26<00:00,  2.07it/s]\n",
      "Evaluating: 100%|███████████████████████████████| 12/12 [00:06<00:00,  1.97it/s]\n",
      "Epoch 21/30:\n",
      "  Train Loss: 0.0433\n",
      "  Val F1: 0.8230, Precision: 0.8790, Recall: 0.7886, Accuracy: 0.9778\n",
      "Training: 100%|█████████████████████████████████| 55/55 [00:28<00:00,  1.90it/s]\n",
      "Evaluating: 100%|███████████████████████████████| 12/12 [00:06<00:00,  1.93it/s]\n",
      "Epoch 22/30:\n",
      "  Train Loss: 0.0437\n",
      "  Val F1: 0.8246, Precision: 0.8855, Recall: 0.7838, Accuracy: 0.9768\n",
      "Training: 100%|█████████████████████████████████| 55/55 [00:28<00:00,  1.90it/s]\n",
      "Evaluating: 100%|███████████████████████████████| 12/12 [00:06<00:00,  1.82it/s]\n",
      "Epoch 23/30:\n",
      "  Train Loss: 0.0433\n",
      "  Val F1: 0.8354, Precision: 0.8978, Recall: 0.7896, Accuracy: 0.9793\n",
      "  New best model saved to ./models/best_model_voc.pth\n",
      "Training: 100%|█████████████████████████████████| 55/55 [00:29<00:00,  1.88it/s]\n",
      "Evaluating: 100%|███████████████████████████████| 12/12 [00:06<00:00,  1.81it/s]\n",
      "Epoch 24/30:\n",
      "  Train Loss: 0.0421\n",
      "  Val F1: 0.8278, Precision: 0.8903, Recall: 0.7821, Accuracy: 0.9777\n",
      "Training: 100%|█████████████████████████████████| 55/55 [00:29<00:00,  1.84it/s]\n",
      "Evaluating: 100%|███████████████████████████████| 12/12 [00:06<00:00,  1.85it/s]\n",
      "Epoch 25/30:\n",
      "  Train Loss: 0.0425\n",
      "  Val F1: 0.8233, Precision: 0.8830, Recall: 0.7917, Accuracy: 0.9764\n",
      "  Checkpoint saved to ./models/checkpoint_voc_epoch_25.pth\n",
      "Training: 100%|█████████████████████████████████| 55/55 [00:30<00:00,  1.83it/s]\n",
      "Evaluating: 100%|███████████████████████████████| 12/12 [00:06<00:00,  1.90it/s]\n",
      "Epoch 26/30:\n",
      "  Train Loss: 0.0434\n",
      "  Val F1: 0.8253, Precision: 0.8842, Recall: 0.7895, Accuracy: 0.9772\n",
      "Training: 100%|█████████████████████████████████| 55/55 [00:29<00:00,  1.89it/s]\n",
      "Evaluating: 100%|███████████████████████████████| 12/12 [00:06<00:00,  1.87it/s]\n",
      "Epoch 27/30:\n",
      "  Train Loss: 0.0426\n",
      "  Val F1: 0.8195, Precision: 0.9231, Recall: 0.7588, Accuracy: 0.9781\n",
      "Training: 100%|█████████████████████████████████| 55/55 [00:28<00:00,  1.90it/s]\n",
      "Evaluating: 100%|███████████████████████████████| 12/12 [00:06<00:00,  1.86it/s]\n",
      "Epoch 28/30:\n",
      "  Train Loss: 0.0419\n",
      "  Val F1: 0.8179, Precision: 0.8837, Recall: 0.7841, Accuracy: 0.9772\n",
      "Training: 100%|█████████████████████████████████| 55/55 [00:29<00:00,  1.88it/s]\n",
      "Evaluating: 100%|███████████████████████████████| 12/12 [00:06<00:00,  1.85it/s]\n",
      "Epoch 29/30:\n",
      "  Train Loss: 0.0442\n",
      "  Val F1: 0.7951, Precision: 0.8947, Recall: 0.7296, Accuracy: 0.9754\n",
      "Training: 100%|█████████████████████████████████| 55/55 [00:29<00:00,  1.86it/s]\n",
      "Evaluating: 100%|███████████████████████████████| 12/12 [00:06<00:00,  1.88it/s]\n",
      "Epoch 30/30:\n",
      "  Train Loss: 0.0414\n",
      "  Val F1: 0.8329, Precision: 0.8664, Recall: 0.8089, Accuracy: 0.9772\n",
      "  Checkpoint saved to ./models/checkpoint_voc_epoch_30.pth\n",
      "\n",
      "Evaluating best model on test set...\n",
      "/kaggle/working/Image-Tagging/train_voc.py:229: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.module.load_state_dict(torch.load(best_model_path))\n",
      "Evaluating: 100%|███████████████████████████████| 12/12 [00:09<00:00,  1.25it/s]\n",
      "Test Results:\n",
      "  F1 Score: 0.8191\n",
      "  Precision: 0.8871\n",
      "  Recall: 0.7658\n",
      "  Accuracy: 0.9751\n"
     ]
    }
   ],
   "source": [
    "!python train_voc.py --voc-dir /kaggle/input/pascal-voc-2007/VOCtrainval_06-Nov-2007/VOCdevkit/VOC2007 --batch-size 32 --epochs 30 --device cuda --image-size 448 --save-dir ./models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T06:02:50.909700Z",
     "iopub.status.busy": "2025-04-02T06:02:50.909342Z",
     "iopub.status.idle": "2025-04-02T06:04:27.830857Z",
     "shell.execute_reply": "2025-04-02T06:04:27.829760Z",
     "shell.execute_reply.started": "2025-04-02T06:02:50.909675Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Found test split file: /kaggle/input/pascal-voc-2007/VOCtest_06-Nov-2007/VOCdevkit/VOC2007/ImageSets/Main/test.txt\n",
      "Looking for VOC data in:\n",
      "  Images: /kaggle/input/pascal-voc-2007/VOCtest_06-Nov-2007/VOCdevkit/VOC2007/JPEGImages\n",
      "  Annotations: /kaggle/input/pascal-voc-2007/VOCtest_06-Nov-2007/VOCdevkit/VOC2007/Annotations\n",
      "  Split file: /kaggle/input/pascal-voc-2007/VOCtest_06-Nov-2007/VOCdevkit/VOC2007/ImageSets/Main/test.txt\n",
      "Processing 4952 images from test split...\n",
      "Loaded 4952 images with 20 classes\n",
      "Evaluating on 4952 test images...\n",
      "Loading model weights from /kaggle/working/Image-Tagging/models/best_model_voc.pth\n",
      "Model loaded successfully\n",
      "Evaluating: 100%|█████████████████████████████| 310/310 [00:32<00:00,  9.62it/s]\n",
      "\n",
      "Evaluation Results on test set:\n",
      "Accuracy: 0.9736\n",
      "Mean Precision: 0.8232\n",
      "Mean Recall: 0.8240\n",
      "Mean F1 Score: 0.8190\n",
      "mAP: 0.8865\n",
      "\n",
      "Top 5 classes by F1 score:\n",
      "  dog: F1=0.9056, Precision=0.9517, Recall=0.8637\n",
      "  bird: F1=0.9104, Precision=0.9442, Recall=0.8789\n",
      "  cat: F1=0.9108, Precision=0.9308, Recall=0.8916\n",
      "  train: F1=0.9522, Precision=0.9432, Recall=0.9614\n",
      "  aeroplane: F1=0.9657, Precision=0.9704, Recall=0.9610\n",
      "\n",
      "Bottom 5 classes by F1 score:\n",
      "  bottle: F1=0.5904, Precision=0.5892, Recall=0.5917\n",
      "  pottedplant: F1=0.6164, Precision=0.6810, Recall=0.5630\n",
      "  chair: F1=0.6546, Precision=0.6819, Recall=0.6294\n",
      "  sofa: F1=0.7059, Precision=0.7019, Recall=0.7099\n",
      "  bus: F1=0.7122, Precision=0.5733, Recall=0.9399\n"
     ]
    }
   ],
   "source": [
    "!python evaluate_voc.py --voc-dir /kaggle/input/pascal-voc-2007/VOCtest_06-Nov-2007/VOCdevkit/VOC2007 --model-path /kaggle/working/Image-Tagging/models/best_model_voc.pth "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 18276,
     "sourceId": 23902,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 857191,
     "sourceId": 1462296,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 288848,
     "modelInstanceId": 267817,
     "sourceId": 317405,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 288917,
     "modelInstanceId": 267888,
     "sourceId": 317495,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
